{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoid Reaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env 요약\n",
    "* Env 객체는 생성자에서 공유메모리를 바로 만들기때문에 학습하기 직전에 생성해주기\n",
    "* 제대로 알아야하는 것이 terminal 조건은 goal 에 닿을 때이다. 리버와 닿으면 점수만 깎이고 게임은 끝나지 않는다. 잘 몰랐음.\n",
    "* `observation` (observation < state)\n",
    "    - raw data 로 json 형태라서 실제로는 파싱해줘야함.\n",
    "* `action` [Agent 의 make_step_msg() 참조](https://github.com/TeamSAIDA/SAIDA_RL/blob/0503b30620e2dcfdfd03fa0bb548b24d4bbb19b5/python/saida_gym/envs/SAIDAGym.py#L137)\n",
    "    - discrete : 360 / div, 마지막 액션은 스탑. one-hot\n",
    "    - continuous 1 : x, y, action type. ??\n",
    "    - continuous 2 : theta, radian, aciton type. ??\n",
    "    - !중요 - dicrete action 은 항상 하나의 스칼라값, continuous action 은 항상 3 개의 값\n",
    "    - 그런데 continuous 라도 좌표값은 integer 로 줘야함. 맵 사이즈 고려해서 범위도 따로 설정해줘야함. - Processor 에서 scale 함수를 통해서\n",
    "    - `angle` action 은 float, `radian` 은 하드코딩으로 고정해야할듯\n",
    "    - 이동거리를 늘리면 accel = True 됨 참조\n",
    "    - mode 1 에서 좌표는 my_unit 기준 좌표임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> raw action : 0\n",
    "\n",
    "> raw observation : my_unit {\n",
    "  unit_type: \"Terran_Dropship\"\n",
    "  hp: 150\n",
    "  pos_x: 49\n",
    "  pos_y: 33\n",
    "  velocity_x: 1.39453125\n",
    "  velocity_y: 0.03125\n",
    "  angle: 0.02454369260617026\n",
    "  accelerating: true\n",
    "}\n",
    "en_unit {\n",
    "  unit_type: \"Protoss_Reaver\"\n",
    "  hp: 100\n",
    "  shield: 80\n",
    "  cooldown: 9\n",
    "  pos_x: 126\n",
    "  pos_y: 278\n",
    "  velocity_x: 2.4140625\n",
    "  velocity_y: 1.78125\n",
    "  angle: 0.6381360077604268\n",
    "  accelerating: true\n",
    "}\n",
    "en_unit {\n",
    "  unit_type: \"Protoss_Reaver\"\n",
    "  hp: 100\n",
    "  shield: 80\n",
    "  cooldown: 8\n",
    "  pos_x: 164\n",
    "  pos_y: 165\n",
    "  velocity_x: -2.16796875\n",
    "  velocity_y: -2.07421875\n",
    "  angle: 3.902447124381071\n",
    "  accelerating: true\n",
    "}\n",
    "en_unit {\n",
    "  unit_type: \"Protoss_Reaver\"\n",
    "  hp: 100\n",
    "  shield: 80\n",
    "  cooldown: 7\n",
    "  pos_x: 256\n",
    "  pos_y: 102\n",
    "  velocity_y: 3.0\n",
    "  angle: 1.5707963267948966\n",
    "  accelerating: true\n",
    "}\n",
    "\n",
    "> raw reward : 0.0\n",
    "\n",
    "> raw done : False\n",
    "\n",
    "> raw info : {'infoMsg': }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "* existing agent 사용하거나\n",
    "* 직접 implementing 할 수 있음.\n",
    "* implementing 할 때, agent 모듈을 상속하고 함수재정의 해야함\n",
    "* `알고리즘`, `학습방법` 을 정의할 수 있다.\n",
    "* `forward`, `backward`, `compile` 등의 메서드를 오버라이드\n",
    "* `local_speed` 인자는 렌더링 속도 관여. 기본값은 0 으로 젤빠름. 50 정도일때 실제 겜속도와 유사\n",
    "* `no_gui` 인자는 렌더링 유무 boolean. 렌더링 안하면 돌리는 속도가 약 2 배 조금 못되게 빨라짐. 글고 아예 렌더링이 안되는것이아님\n",
    "* model 은 따로 만들어서 agent 인자로 주기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor\n",
    "* Env 와 Agent 데이터교환을 해준다.\n",
    "* 데이터들을 모두 셋팅해줄수 있다.\n",
    "* `process_action`, `process_step`, `process_observation` 등의 메서드를 오버라이드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참조 & 주의\n",
    "* `env.close()` - 학습이 끝나고 스타 종료\n",
    "* env 생성시, `local_speed` 인자는 render 속도 조절, 0 이 최고속도\n",
    "* agent 의 `compile()` 메서드에서 `self.compiled=True` 를 꼭 해줘야함.\n",
    "* Processor 는 반드시 만들어야함\n",
    "* Processor 의 `processor_action()` 의 반환값은 iteratable 해야함. 경우에 따라 2-d 형태로 반환\n",
    "* Agent 의 `make_step_msg()` 를 참조하면 액션모드에 따라 넘겨줄 액션형태를 유추할 수 있다.\n",
    "* jupyter 에서 현재 디렉 찾는 방법 `os.path.basename('')`\n",
    "* load data 할 때 OSERROR 날 때 - 한글경로 포함주의\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN\n",
    "* 수정\n",
    "* 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO - discrete\n",
    "* 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 커스텀\n",
    "* 건드는 부분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO - continuous 1\n",
    "* 결과"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
