{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2019 SAMSUNG SDS <Team.SAIDA@gmail.com>\n",
    "#\n",
    "# This code is distribued under the terms and conditions from the MIT License (MIT).\n",
    "#\n",
    "# Authors : Uk Jo, Iljoo Yoon, Hyunjae Lee, Daehun Jun\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "from core.common.processor import Processor\n",
    "from core.algorithm.REINFORCE import ReinforceAgent\n",
    "from core.callbacks import DrawTrainMovingAvgPlotCallback\n",
    "from saida_gym.starcraft.avoidReavers import AvoidReavers\n",
    "import saida_gym.envs.conn.connection_env as Config\n",
    "\n",
    "from keras.layers import Dense, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Hyper Parameter\n",
    "EPISODES = 5000\n",
    "LEARNING_RATE = 0.0004\n",
    "# 5 features of a Dropship  + 6 features of 3 Reavers\n",
    "STATE_SIZE = 5 + 3 * 6\n",
    "\n",
    "\n",
    "def scale_velocity(v):\n",
    "    return v\n",
    "\n",
    "\n",
    "def scale_coordinate(pos):\n",
    "    return np.tanh(int(pos / 16) / 20)\n",
    "\n",
    "\n",
    "def scale_angle(angle):\n",
    "    return (angle - math.pi) / math.pi\n",
    "\n",
    "\n",
    "def scale_pos(pos):\n",
    "    return int(pos / 16)\n",
    "\n",
    "\n",
    "def scale_pos2(pos):\n",
    "    return int(pos / 8)\n",
    "\n",
    "\n",
    "# preprocess for observation\n",
    "def reward_reshape(reward):\n",
    "    \"\"\"Reshape the reward\n",
    "\n",
    "        Starcraft Env returns the reward according to following conditions.\n",
    "\n",
    "        1. Invalid action : -0.1\n",
    "        2. get hit : -1\n",
    "        3. goal : 1\n",
    "        4. others : 0\n",
    "\n",
    "    # Argument\n",
    "        reward (float): The observed reward after executing the action\n",
    "\n",
    "    # Returns\n",
    "        reshaped reward\n",
    "    \"\"\"\n",
    "    if math.fabs(reward + 0.1) < 0.01:\n",
    "        reward = -5\n",
    "    elif reward == 0:\n",
    "        reward = -0.1\n",
    "    elif reward == -1:\n",
    "        reward = -3\n",
    "    elif reward == 1:\n",
    "        reward = 2\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "class ReaverProcessor(Processor):\n",
    "    def __init__(self):\n",
    "        self.last_action = None\n",
    "\n",
    "    def process_action(self, action):\n",
    "        self.last_action = action\n",
    "        return action\n",
    "\n",
    "    def process_step(self, observation, reward, done, info):\n",
    "        state_array = self.process_observation(observation)\n",
    "        reward = reward_reshape(reward)\n",
    "        return state_array, reward, done, info\n",
    "\n",
    "    def process_observation(self, observation, **kwargs):\n",
    "        \"\"\" Pre-process observation\n",
    "\n",
    "        # Argument\n",
    "            observation (object): The current observation from the environment.\n",
    "\n",
    "        # Returns\n",
    "            processed observation\n",
    "\n",
    "        \"\"\"\n",
    "        if len(observation.my_unit) > 0:\n",
    "            s = np.zeros(STATE_SIZE)\n",
    "            me = observation.my_unit[0]\n",
    "            # Observation for Dropship\n",
    "            s[0] = scale_pos(me.pos_x)  # X of coordinates\n",
    "            s[1] = scale_pos(me.pos_y)  # Y of coordinates\n",
    "            s[2] = scale_velocity(me.velocity_x)  # X of velocity\n",
    "            s[3] = scale_velocity(me.velocity_y)  # y of coordinates\n",
    "            s[4] = scale_angle(me.angle)  # Angle of head of dropship\n",
    "\n",
    "            # Observation for Reavers\n",
    "            for ind, ob in enumerate(observation.en_unit):\n",
    "                s[ind * 6 + 5] = scale_pos(ob.pos_x - me.pos_x)  # X of relative coordinates\n",
    "                s[ind * 6 + 6] = scale_pos(ob.pos_y - me.pos_y)  # Y of relative coordinates\n",
    "                s[ind * 6 + 7] = scale_velocity(ob.velocity_x)  # X of velocity\n",
    "                s[ind * 6 + 8] = scale_velocity(ob.velocity_y)  # Y of velocity\n",
    "                s[ind * 6 + 9] = scale_angle(ob.angle)  # Angle of head of Reavers\n",
    "                s[ind * 6 + 10] = scale_angle(1 if ob.accelerating else 0)  # True if Reaver is accelerating\n",
    "\n",
    "        return s\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    TRAINING_MODE = True\n",
    "    FILE_NAME = os.path.basename(__file__).split('.')[0] + \"-\" + datetime.now().strftime(\"%m%d%H%M%S\")\n",
    "\n",
    "    # todo : need to substitute it with env.make() and also remove other parameters such as protobuf_name & verbose!?\n",
    "    # Create an Environment\n",
    "    env = AvoidReavers( move_angle=30, move_dist=3, frames_per_step=24)\n",
    "    action_size = env.action_space.n\n",
    "\n",
    "    # Create your model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(70, input_dim=STATE_SIZE, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(40, activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(action_size, activation='softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    # Create your Agent\n",
    "    agent = ReinforceAgent(STATE_SIZE, action_size, processor=ReaverProcessor(), model=model,\n",
    "                           discount_factor=0.9)\n",
    "\n",
    "    agent.compile(Adam(lr=LEARNING_RATE))\n",
    "\n",
    "    # For the Graph\n",
    "    cb_plot = DrawTrainMovingAvgPlotCallback('../../save_graph/' + FILE_NAME + '.png', 10, 5, l_label=['episode_reward'])\n",
    "\n",
    "    # Run your agent\n",
    "    agent.run(env, EPISODES * 100, train_mode=TRAINING_MODE, verbose=2, callbacks=[cb_plot])\n",
    "\n",
    "    agent.save_weights(FILE_NAME + '.h5f', False)\n",
    "\n",
    "    env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
